BNCparse
================

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

``` python
```

    The autoreload extension is already loaded. To reload it, use:
      %reload_ext autoreload

Quirin Würschinger, LMU Munich

<q.wuerschinger@lmu.de>

## Data overview

<div>

<p>

<img src="index_files/figure-commonmark/mermaid-figure-1.png"
style="width:7in;height:8.08in" />

</p>

</div>

# Load packages

Package requirements are stored in `requirements.yml`.

# Variables

BNC2014 needs to be downloaded for this script to work. It can be
obtained from the official [BNC
website](http://corpora.lancs.ac.uk/bnc2014/).

The following variables need to be updated to the corpus’ local path. In
the current setting the BNC2014 data were stored in the project folder
in the folder `data/bnc-2014-spoken`.

For development, I use a small subset of the corpus contained in
`data/test` that only contains the first 10 texts.

``` python
testing = True

if testing:
    path_bnc = Path('../data/test/bnc-2014-spoken')
    assert path_bnc.exists()
    texts_n = 10
    tokens_n = 94_659
else:
    path_bnc = Path('../data/bnc-2014-spoken')
    assert path_bnc.exists()
    texts_n = 1251
    tokens_n = 11_422_615
```

``` python
path_corpus = Path(path_bnc / 'spoken' / 'tagged')
assert path_corpus.exists()
path_metadata = Path(path_bnc / 'spoken' / 'metadata')
assert path_metadata.exists()
```

``` python
fp_meta_speakers = Path('../data/bnc-2014-spoken/spoken/metadata/bnc2014spoken-speakerdata.tsv')
assert fp_meta_speakers.exists()
fp_meta_speakers_fields = Path('../data/bnc-2014-spoken/spoken/metadata/metadata-fields-speaker.txt')
assert fp_meta_speakers_fields.exists()
fp_meta_texts = Path('../data/bnc-2014-spoken/spoken/metadata/bnc2014spoken-textdata.tsv')
assert fp_meta_texts.exists()
fp_meta_texts_fields = Path('../data/bnc-2014-spoken/spoken/metadata/metadata-fields-text.txt')
assert fp_meta_texts_fields.exists()
```

# Load and parse XML

``` python
path_texts = list(path_corpus.glob('*.xml'))
```

``` python
assert len(path_texts) == texts_n
```

------------------------------------------------------------------------

<a
href="https://github.com/wuqui/bncparse/blob/main/bncparse/core.py#L15"
target="_blank" style="float:right; font-size:smaller">source</a>

### get_xml

>      get_xml (f_path)

``` python
texts = [get_xml(path) for path in path_texts]
```

# Corpus statistics

## Texts

Calculate the total number of texts in the corpus.

``` python
text_ids = [xml.get('id') for xml in texts]

print(f"number of documents in the corpus: {len(text_ids)}")
```

``` python
assert len(text_ids) == texts_n
```

## Speakers

1.  Determine all speakers in the corpus.
2.  Calculate the total number of words each speaker has contributed to
    the corpus.

``` python
speakers_words = defaultdict(int)
for text in texts:
    for u in text.iter('u'):
        speaker = u.get('who')
        n_words = len([w for w in u.iter('w')])
        speakers_words[speaker] += n_words
```

### Number of speakers

``` python
print(f"number of speakers: {len(speakers_words)}")
```

### Words per speaker

``` python
df_speakers_tokens = pd.DataFrame(
    list(speakers_words.items()), columns=['speaker', 'tokens'])
df_speakers_tokens = df_speakers_tokens.sort_values('tokens', ascending=False)
df_speakers_tokens
```

The table containing all speakers and their total token counts can be
found in `speakers_tokens.csv`.

``` python
if not testing:
    df_speakers_tokens.to_csv('../out/speakers_tokens.csv', index=False)
```

## Vocabulary

``` python
tokens = []
for text in texts:
    for w in text.iter('w'):
        tokens.append(w.text)
```

``` python
n_toks_types = pd.DataFrame(
    {'tokens': f'{len(tokens):,}', 
    'types': f'{len(set(tokens)):,}'}, 
    index=[0]
)

n_toks_types
```

# Export corpus data in tabular format

In addition to the metadata present in the corpus, I’ve added three
columns providing positional information about the tokens:

- `u_toks`: total number of tokens in the given utterance
- `w_idx`: token position (‘index’) in the given utterance, starting at
  1
- `w_idx_rel`: relative token position in the given utterance:
  `w_idx / u_toks`

``` python
tokens = []

for text in texts:
    for u in text.findall('u'):
        for i, w in enumerate(u.iter('w')):
            tok_d = {}

            tok_d['text_id'] = text.get('id')

            tok_d['u_n'] = u.get('n')
            tok_d['u_who'] = u.get('who')
            tok_d['u_trans'] = u.get('trans')
            tok_d['u_whoConfidence'] = u.get('whoConfidence')
            tok_d['u_toks'] = len(list(u.iter('w')))

            tok_d['w_pos'] = w.get('pos')
            tok_d['w_lemma'] = w.get('lemma')
            tok_d['w_class'] = w.get('class')
            tok_d['w_usas'] = w.get('usas')
            tok_d['w_text'] = w.text
            tok_d['w_idx'] = i + 1
            tok_d['w_idx_rel'] = round(tok_d['w_idx'] / tok_d['u_toks'], 2)

            tokens.append(tok_d)
```

``` python
tokens = pd.DataFrame(tokens)
```

``` python
tokens.head(50)
```

``` python
assert len(tokens) == tokens_n
```

I export the full token table to `tokens.csv`.

``` python
if not testing:
    tokens.to_csv('../out/tokens.csv', index=False)
```

I also export a smaller version for use in spreadsheet software. This
version contains the first 50,000 tokens in the corpus and is stored in
`tokens_50k.csv`.

``` python
if not testing:
    (tokens
     .head(50_000)
     .to_csv('../out/tokens_50k.csv', index=False))
```

# Add metadata

## Speakers

``` python
meta_speakers_head = pd.read_csv(
    fp_meta_speakers_fields,
    delimiter='\t',
    skiprows=1,
    index_col=0
)
```

``` python
meta_speakers_head
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>XML tag</th>
      <th>Metadata Title</th>
    </tr>
    <tr>
      <th>#</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>exactage</td>
      <td>Exact age</td>
    </tr>
    <tr>
      <th>2</th>
      <td>age1994</td>
      <td>Age (BNC1994 groups)</td>
    </tr>
    <tr>
      <th>3</th>
      <td>agerange</td>
      <td>Age range</td>
    </tr>
    <tr>
      <th>4</th>
      <td>gender</td>
      <td>Gender</td>
    </tr>
    <tr>
      <th>5</th>
      <td>nat</td>
      <td>Nationality</td>
    </tr>
    <tr>
      <th>6</th>
      <td>birthplace</td>
      <td>Place of birth</td>
    </tr>
    <tr>
      <th>7</th>
      <td>birthcountry</td>
      <td>Country of birth</td>
    </tr>
    <tr>
      <th>8</th>
      <td>l1</td>
      <td>First language</td>
    </tr>
    <tr>
      <th>9</th>
      <td>lingorig</td>
      <td>Linguistic origin</td>
    </tr>
    <tr>
      <th>10</th>
      <td>dialect_rep</td>
      <td>Accent/dialect as reported</td>
    </tr>
    <tr>
      <th>11</th>
      <td>hab_city</td>
      <td>City/town living</td>
    </tr>
    <tr>
      <th>12</th>
      <td>hab_country</td>
      <td>Country living</td>
    </tr>
    <tr>
      <th>13</th>
      <td>hab_dur</td>
      <td>Duration living (years)</td>
    </tr>
    <tr>
      <th>14</th>
      <td>dialect_l1</td>
      <td>Dialect at Level 1</td>
    </tr>
    <tr>
      <th>15</th>
      <td>dialect_l2</td>
      <td>Dialect at Level 2</td>
    </tr>
    <tr>
      <th>16</th>
      <td>dialect_l3</td>
      <td>Dialect at Level 3</td>
    </tr>
    <tr>
      <th>17</th>
      <td>dialect_l4</td>
      <td>Dialect at Level 4</td>
    </tr>
    <tr>
      <th>18</th>
      <td>edqual</td>
      <td>Highest qualification</td>
    </tr>
    <tr>
      <th>19</th>
      <td>occupation</td>
      <td>Occupation: title</td>
    </tr>
    <tr>
      <th>20</th>
      <td>socgrade</td>
      <td>Class: Social grade</td>
    </tr>
    <tr>
      <th>21</th>
      <td>nssec</td>
      <td>Class: NS-SEC</td>
    </tr>
    <tr>
      <th>22</th>
      <td>l2</td>
      <td>L2 (if bilingual)</td>
    </tr>
    <tr>
      <th>23</th>
      <td>fls</td>
      <td>Foreign languages spoken</td>
    </tr>
    <tr>
      <th>24</th>
      <td>in_core</td>
      <td>Part of core set of speakers</td>
    </tr>
  </tbody>
</table>
</div>

``` python
meta_speakers = pd.read_csv(
    fp_meta_speakers, 
    delimiter='\t', 
    names=meta_speakers_head['XML tag'],
    index_col=0
)
```

``` python
meta_speakers
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>exactage</th>
      <th>age1994</th>
      <th>agerange</th>
      <th>gender</th>
      <th>nat</th>
      <th>birthplace</th>
      <th>birthcountry</th>
      <th>l1</th>
      <th>lingorig</th>
      <th>dialect_rep</th>
      <th>...</th>
      <th>dialect_l2</th>
      <th>dialect_l3</th>
      <th>dialect_l4</th>
      <th>edqual</th>
      <th>occupation</th>
      <th>socgrade</th>
      <th>nssec</th>
      <th>l2</th>
      <th>fls</th>
      <th>in_core</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>S0001</th>
      <td>32</td>
      <td>25_34</td>
      <td>30_39</td>
      <td>F</td>
      <td>British</td>
      <td>Wordsley, West Midlands</td>
      <td>England</td>
      <td>English</td>
      <td>England</td>
      <td>None indicated</td>
      <td>...</td>
      <td>unspecified</td>
      <td>unspecified</td>
      <td>unspecified</td>
      <td>5_postgrad</td>
      <td>University researcher</td>
      <td>A</td>
      <td>1_2</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>n</td>
    </tr>
    <tr>
      <th>S0002</th>
      <td>NaN</td>
      <td>Unknown</td>
      <td>19_29</td>
      <td>F</td>
      <td>British</td>
      <td>Birmingham</td>
      <td>England</td>
      <td>English</td>
      <td>England</td>
      <td>Midlands</td>
      <td>...</td>
      <td>england</td>
      <td>midlands</td>
      <td>unspecified</td>
      <td>5_postgrad</td>
      <td>Teacher</td>
      <td>B</td>
      <td>2</td>
      <td>NaN</td>
      <td>Japanese -- Intermediate</td>
      <td>n</td>
    </tr>
    <tr>
      <th>S0003</th>
      <td>NaN</td>
      <td>Unknown</td>
      <td>19_29</td>
      <td>F</td>
      <td>British</td>
      <td>Royal Leamington Spa, Warwickshire</td>
      <td>England</td>
      <td>English</td>
      <td>England</td>
      <td>Northern</td>
      <td>...</td>
      <td>england</td>
      <td>north</td>
      <td>unspecified</td>
      <td>4_graduate</td>
      <td>Student</td>
      <td>E</td>
      <td>uncat</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>n</td>
    </tr>
    <tr>
      <th>S0004</th>
      <td>NaN</td>
      <td>Unknown</td>
      <td>30_39</td>
      <td>M</td>
      <td>British</td>
      <td>NaN</td>
      <td>Germany</td>
      <td>English</td>
      <td>England</td>
      <td>Northern</td>
      <td>...</td>
      <td>england</td>
      <td>north</td>
      <td>unspecified</td>
      <td>5_postgrad</td>
      <td>Engineer</td>
      <td>C2</td>
      <td>5</td>
      <td>NaN</td>
      <td>Spanish -- Beginner</td>
      <td>n</td>
    </tr>
    <tr>
      <th>S0005</th>
      <td>NaN</td>
      <td>60plus</td>
      <td>80_89</td>
      <td>F</td>
      <td>British</td>
      <td>Birmingham</td>
      <td>England</td>
      <td>English</td>
      <td>England</td>
      <td>Midlands</td>
      <td>...</td>
      <td>england</td>
      <td>midlands</td>
      <td>unspecified</td>
      <td>2_secondary</td>
      <td>Insurance Broker (retired)</td>
      <td>E</td>
      <td>8</td>
      <td>NaN</td>
      <td>French -- Beginner</td>
      <td>n</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>S0691</th>
      <td>45</td>
      <td>45_59</td>
      <td>40_49</td>
      <td>F</td>
      <td>British</td>
      <td>Barrow-In-Furness</td>
      <td>UK</td>
      <td>English</td>
      <td>England</td>
      <td>Northern/ Cumbrian</td>
      <td>...</td>
      <td>england</td>
      <td>north</td>
      <td>unspecified</td>
      <td>3_sixthform</td>
      <td>dental nurse (trainee)</td>
      <td>D</td>
      <td>6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>y</td>
    </tr>
    <tr>
      <th>S0692</th>
      <td>22</td>
      <td>15_24</td>
      <td>19_29</td>
      <td>M</td>
      <td>British</td>
      <td>Barrow-in-Furness</td>
      <td>England</td>
      <td>English</td>
      <td>England</td>
      <td>Northern</td>
      <td>...</td>
      <td>england</td>
      <td>north</td>
      <td>unspecified</td>
      <td>3_sixthform</td>
      <td>Sales Assistant (Part time)</td>
      <td>D</td>
      <td>6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>n</td>
    </tr>
    <tr>
      <th>UNKFEMALE</th>
      <td>NaN</td>
      <td>Unknown</td>
      <td>Unknown</td>
      <td>F</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None indicated</td>
      <td>...</td>
      <td>unspecified</td>
      <td>unspecified</td>
      <td>unspecified</td>
      <td>9_unknown</td>
      <td>NaN</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>n</td>
    </tr>
    <tr>
      <th>UNKMALE</th>
      <td>NaN</td>
      <td>Unknown</td>
      <td>Unknown</td>
      <td>M</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None indicated</td>
      <td>...</td>
      <td>unspecified</td>
      <td>unspecified</td>
      <td>unspecified</td>
      <td>9_unknown</td>
      <td>NaN</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>n</td>
    </tr>
    <tr>
      <th>UNKMULTI</th>
      <td>NaN</td>
      <td>Unknown</td>
      <td>Unknown</td>
      <td>X</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None indicated</td>
      <td>...</td>
      <td>unspecified</td>
      <td>unspecified</td>
      <td>unspecified</td>
      <td>9_unknown</td>
      <td>NaN</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>n</td>
    </tr>
  </tbody>
</table>
<p>671 rows × 24 columns</p>
</div>

## Texts

``` python
meta_texts_head = pd.read_csv(
    fp_meta_texts_fields,
    delimiter='\t',
    skiprows=1,
    index_col=0
)
```

``` python
meta_texts_head
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>XML tag</th>
      <th>Metadata Title</th>
    </tr>
    <tr>
      <th>#</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>rec_length</td>
      <td>Recording length</td>
    </tr>
    <tr>
      <th>2</th>
      <td>rec_date</td>
      <td>Recording date</td>
    </tr>
    <tr>
      <th>3</th>
      <td>rec_year</td>
      <td>Year of recording</td>
    </tr>
    <tr>
      <th>4</th>
      <td>rec_period</td>
      <td>Recording period</td>
    </tr>
    <tr>
      <th>5</th>
      <td>n_speakers</td>
      <td>Number of speakers</td>
    </tr>
    <tr>
      <th>6</th>
      <td>list_speakers</td>
      <td>List of speaker IDs</td>
    </tr>
    <tr>
      <th>7</th>
      <td>rec_loc</td>
      <td>Recording location</td>
    </tr>
    <tr>
      <th>8</th>
      <td>relationships</td>
      <td>Inter-speaker relationship</td>
    </tr>
    <tr>
      <th>9</th>
      <td>topics</td>
      <td>Topics covered</td>
    </tr>
    <tr>
      <th>10</th>
      <td>activity</td>
      <td>Activity description</td>
    </tr>
    <tr>
      <th>11</th>
      <td>conv_type</td>
      <td>Selected characterisations of conversation type</td>
    </tr>
    <tr>
      <th>12</th>
      <td>conventions</td>
      <td>Transcription conventions used</td>
    </tr>
    <tr>
      <th>13</th>
      <td>in_sample</td>
      <td>Sample release inclusion</td>
    </tr>
    <tr>
      <th>14</th>
      <td>transcriber</td>
      <td>Transcriber</td>
    </tr>
  </tbody>
</table>
</div>

``` python
meta_texts = pd.read_csv(
    fp_meta_texts, 
    delimiter='\t', 
    names=meta_texts_head['XML tag'],
    index_col=0
)
```

``` python
meta_texts
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rec_length</th>
      <th>rec_date</th>
      <th>rec_year</th>
      <th>rec_period</th>
      <th>n_speakers</th>
      <th>list_speakers</th>
      <th>rec_loc</th>
      <th>relationships</th>
      <th>topics</th>
      <th>activity</th>
      <th>conv_type</th>
      <th>conventions</th>
      <th>in_sample</th>
      <th>transcriber</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>S23A</th>
      <td>1:50:43</td>
      <td>2014-12-27</td>
      <td>2014</td>
      <td>2014_Q4</td>
      <td>4</td>
      <td>S0021 S0032 S0094 S0095</td>
      <td>Speakers' home</td>
      <td>Close family, partners, very close friends</td>
      <td>Computer programming, food, wine, temperature,...</td>
      <td>Catching up with family over food and presents</td>
      <td>Discussing, explaining, anecdote telling</td>
      <td>Revised</td>
      <td>n</td>
      <td>T15</td>
    </tr>
    <tr>
      <th>S24A</th>
      <td>0:17:24</td>
      <td>2014-09-12</td>
      <td>2014</td>
      <td>2014_Q3</td>
      <td>2</td>
      <td>S0261 S0262</td>
      <td>Modern Art Museum, London</td>
      <td>Close family, partners, very close friends</td>
      <td>The art</td>
      <td>A couple discussing modern art at a museum</td>
      <td>Discussing, explaining, inquiring</td>
      <td>Revised</td>
      <td>y</td>
      <td>T09</td>
    </tr>
    <tr>
      <th>S24D</th>
      <td>0:20:00</td>
      <td>2016-01-14</td>
      <td>2016</td>
      <td>2016_Q1</td>
      <td>3</td>
      <td>S0653 S0654 S0655</td>
      <td>Home kitchen, Comberton</td>
      <td>Close family, partners, very close friends</td>
      <td>Lego Ninjago, Minecraft worlds</td>
      <td>Spending time on electronic toys instead of re...</td>
      <td>Discusing, explaining</td>
      <td>Revised</td>
      <td>n</td>
      <td>T18</td>
    </tr>
    <tr>
      <th>S24E</th>
      <td>0:45:53</td>
      <td>2015-09-15</td>
      <td>2015</td>
      <td>2015_Q3</td>
      <td>3</td>
      <td>S0519 S0520 S0521</td>
      <td>Hunsonby, Cumbria</td>
      <td>Close family, partners, very close friends</td>
      <td>food, exercise, choir, family plans, family me...</td>
      <td>Midweek family dinner</td>
      <td>Discussing, explaining, Inquiring, advising, a...</td>
      <td>Revised</td>
      <td>n</td>
      <td>T09</td>
    </tr>
    <tr>
      <th>S263</th>
      <td>2:00:00</td>
      <td>2016-02-07</td>
      <td>2016</td>
      <td>2016_Q1</td>
      <td>4</td>
      <td>S0588 S0589 S0590 S0616</td>
      <td>ANON’s home</td>
      <td>Close family, partners, very close friends</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Discussing, explaining</td>
      <td>Revised</td>
      <td>n</td>
      <td>T10</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>SZVB</th>
      <td>1:00:31</td>
      <td>2015-11-02</td>
      <td>2015</td>
      <td>2015_Q4</td>
      <td>2</td>
      <td>S0517 S0525</td>
      <td>(ANON’s home, Fradley, Staffs)</td>
      <td>Close family, partners, very close friends</td>
      <td>Babies, family, friends</td>
      <td>Sisters talking about their family (new baby d...</td>
      <td>Discussing, explaining, inquiring, anecdote te...</td>
      <td>Revised</td>
      <td>n</td>
      <td>T15</td>
    </tr>
    <tr>
      <th>SZVC</th>
      <td>0:32:00</td>
      <td>2015-09-14</td>
      <td>2015</td>
      <td>2015_Q3</td>
      <td>2</td>
      <td>S0324 S0325</td>
      <td>ANON's home, Linton</td>
      <td>Close family, partners, very close friends</td>
      <td>school orchestra (windband), Playing the Clari...</td>
      <td>Friends talking about school</td>
      <td>discussing, explaining, inquiring, complaining...</td>
      <td>Revised</td>
      <td>n</td>
      <td>T10</td>
    </tr>
    <tr>
      <th>SZW4</th>
      <td>0:21:09</td>
      <td>2015-10-19</td>
      <td>2015</td>
      <td>2015_Q4</td>
      <td>2</td>
      <td>S0509 S0510</td>
      <td>ANON &amp; ANON's home, Hastings</td>
      <td>Close family, partners, very close friends</td>
      <td>Poetry, Morning Routine, Food, Social Events, ...</td>
      <td>Mother and Daughter</td>
      <td>Discussing, inquiring, anecdote telling</td>
      <td>Revised</td>
      <td>n</td>
      <td>T18</td>
    </tr>
    <tr>
      <th>SZXQ</th>
      <td>0:40:44</td>
      <td>2012-03-21</td>
      <td>2012</td>
      <td>2012_Q1</td>
      <td>2</td>
      <td>S0058 S0120</td>
      <td>Botanic Gardens, Cambridge</td>
      <td>Friends, wider family circle</td>
      <td>TV, languages, friends, holidays, offices, comedy</td>
      <td>NaN</td>
      <td>Discussing, explaining, inquiring, complaining...</td>
      <td>Original</td>
      <td>y</td>
      <td>T11</td>
    </tr>
    <tr>
      <th>SZYV</th>
      <td>0:21:20</td>
      <td>2015-11-04</td>
      <td>2015</td>
      <td>2015_Q4</td>
      <td>2</td>
      <td>S0428 S0432</td>
      <td>Cambridge University Press Printing House</td>
      <td>Friends, wider family circle</td>
      <td>Babies, moving house, sharing clothes, sibling...</td>
      <td>Lunchtime chat</td>
      <td>Discussing, explaining, inquiring</td>
      <td>Revised</td>
      <td>n</td>
      <td>T19</td>
    </tr>
  </tbody>
</table>
<p>1251 rows × 14 columns</p>
</div>

## Merge tokens with speaker & text metadata

df_merged = pd.merge(df_hits, speakers, left_on=‘speaker’,
right_on=speakers.index)

df_merged = pd.merge(df_merged, texts, left_on=‘doc’,
right_on=texts.index)

df_merged.head()

# read tsv files

pd.read_csv(fp_meta_texts, sep=’, header=None)

# read starting in line 3

pd.read_csv(fp_meta_texts_fields, sep=’, header=None, skiprows=3)
