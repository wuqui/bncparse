{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BNCparse\n",
    "\n",
    "> Parsing the BNC2014 Spoken with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quirin Würschinger, LMU Munich\n",
    "\n",
    "[q.wuerschinger@lmu.de](mailto:q.wuerschinger@lmu.de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagram below illustrates all of the data that is currently available. Variables that have been added to what was available from the downloadable version of the BNC are marked with a `+` prefix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "%%| fig-width: 7\n",
    "classDiagram\n",
    "\n",
    "class text {\n",
    "    <<conversation>>\n",
    "    text_id : \"Text ID\"\n",
    "}\n",
    "\n",
    "class u {\n",
    "    <<utterances.csv>>\n",
    "    n : \"Consecutive utterance number\"\n",
    "    who : \"Speaker ID\"\n",
    "    trans : \"Transition type\"\n",
    "    whoConfidence: \"Attribution confidence\"\n",
    "\n",
    "    + u_toks_n : \"Number of tokens in the utterance\"\n",
    "}\n",
    "\n",
    "class w {\n",
    "    <<tokens.csv>>\n",
    "    pos : \"part-of-speech tag [CLAWS]\"\n",
    "    lemma : \"lemmatised form\"\n",
    "    class : \"“simple” POS tag or major word-class\"\n",
    "    usas : \"semantic tag [USAS]\"\n",
    "\n",
    "    + w_idx : \"token position in the given utterance\"\n",
    "    + w_idx_rel : \"relative token position in the given utterance\"\n",
    "    + w_L1 : \"preceding token\"\n",
    "    + w_R1 : = \"subsequent token\n",
    "}\n",
    "\n",
    "class meta_speaker {\n",
    "    <<speakers.csv>>\n",
    "    id : \"Speaker ID\"\n",
    "    exactage : \"Exact age\"\n",
    "    age1994 : \"Age [BNC1994 groups]\"\n",
    "    agerange : \"Age range\"\n",
    "    gender : \"Gender\"\n",
    "    nat : \"Nationality\"\n",
    "    birthplace : \"Place of birth\"\n",
    "    birthcountry : \"Country of birth\"\n",
    "    l1 : \"First language\"\n",
    "    lingorig : \"Linguistic origin\"\n",
    "    dialect_rep : \"Accent/dialect as reported\"\n",
    "    hab_city : \"City/town living\"\n",
    "    hab_country : \"Country living\"\n",
    "    hab_dur : \"Duration living [years]\"\n",
    "    dialect_l1 : \"Dialect at Level 1\"\n",
    "    dialect_l2 : \"Dialect at Level 2\"\n",
    "    dialect_l3 : \"Dialect at Level 3\"\n",
    "    dialect_l4 : \"Dialect at Level 4\"\n",
    "    edqual : \"Highest qualification\"\n",
    "    occupation : \"Occupation: title\"\n",
    "    socgrade : \"Class: Social grade\"\n",
    "    nssec : \"Class: NS-SEC\"\n",
    "    l2 : \"L2 [if bilingual]\"\n",
    "    fls : \"Foreign languages spoken\"\n",
    "    in_core : \"Part of core set of speakers\"\n",
    "    + speaker_toks_n : \"Total number of tokens\"\n",
    "}\n",
    "\n",
    "class meta_text {\n",
    "    <<texts.csv>>\n",
    "    text_id : \"Text ID\"\n",
    "    rec_length : \"Recording length\"\n",
    "    rec_date : \"Recording date\"\n",
    "    rec_year : \"Year of recording\"\n",
    "    rec_period : \"Recording period\"\n",
    "    n_speakers : \"Number of speakers\"\n",
    "    list_speakers : \"List of speaker IDs\"\n",
    "    rec_loc : \"Recording location\"\n",
    "    relationships : \"Inter-speaker relationship\"\n",
    "    topics : \"Topics covered\"\n",
    "    activity : \"Activity description\"\n",
    "    conv_type : \"Selected characterisations of conversation type\"\n",
    "    conventions : \"Transcription conventions used\"\n",
    "    in_sample : \"Sample release inclusion\"\n",
    "    transcriber : \"Transcriber\"\n",
    "}\n",
    "\n",
    "text ..* u : contains\n",
    "u ..* w : contains\n",
    "text .. meta_text : text_id\n",
    "u .. meta_speaker : who\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages\n",
    "\n",
    "Package requirements are stored in `requirements.yml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "from lxml import etree\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For development, I use a small subset of the corpus contained in `data/test` that only contains the first 10 texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = False\n",
    "\n",
    "if testing:\n",
    "    path_bnc = Path('../data/test/bnc-2014-spoken')\n",
    "    assert path_bnc.exists()\n",
    "    texts_n = 10\n",
    "    tokens_n = 94_659\n",
    "else:\n",
    "    path_bnc = Path('../data/bnc-2014-spoken')\n",
    "    assert path_bnc.exists()\n",
    "    texts_n = 1251\n",
    "    tokens_n = 11_422_615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_corpus = Path(path_bnc / 'spoken' / 'tagged')\n",
    "path_metadata = Path(path_bnc / 'spoken' / 'metadata')\n",
    "fp_meta_speakers = Path('../data/bnc-2014-spoken/spoken/metadata/bnc2014spoken-speakerdata.tsv')\n",
    "fp_meta_speakers_fields = Path('../data/bnc-2014-spoken/spoken/metadata/metadata-fields-speaker.txt')\n",
    "fp_meta_texts = Path('../data/bnc-2014-spoken/spoken/metadata/bnc2014spoken-textdata.tsv')\n",
    "fp_meta_texts_fields = Path('../data/bnc-2014-spoken/spoken/metadata/metadata-fields-text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert path_corpus.exists()\n",
    "assert path_metadata.exists()\n",
    "assert fp_meta_speakers.exists()\n",
    "assert fp_meta_speakers_fields.exists()\n",
    "assert fp_meta_texts.exists()\n",
    "assert fp_meta_texts_fields.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and parse XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_texts = list(path_corpus.glob('*.xml'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(path_texts) == texts_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_xml(f_path):\n",
    "    with open(f_path, 'r') as f:\n",
    "        f = f.read()\n",
    "    xml = etree.fromstring(f)\n",
    "    return xml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [get_xml(path) for path in path_texts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_texts_head = pd.read_csv(\n",
    "    fp_meta_texts_fields,\n",
    "    delimiter='\\t',\n",
    "    skiprows=1,\n",
    "    index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_texts = pd.read_csv(\n",
    "    fp_meta_texts, \n",
    "    delimiter='\\t', \n",
    "    names=meta_texts_head['XML tag'],\n",
    "    index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add number of tokens per text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_tokens = []\n",
    "\n",
    "for text in texts:\n",
    "    text_d = {}\n",
    "    text_d['text_id'] = text.get('id')\n",
    "    text_d['text_toks_n'] = 0\n",
    "    for tok in text.iter('w'):\n",
    "        text_d['text_toks_n'] += 1\n",
    "    texts_tokens.append(text_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text_toks_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>16644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S2CY</td>\n",
       "      <td>2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S2AJ</td>\n",
       "      <td>4161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S2B5</td>\n",
       "      <td>7372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S2DD</td>\n",
       "      <td>11452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S2A5</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S2AX</td>\n",
       "      <td>14492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S2E2</td>\n",
       "      <td>4883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S2C9</td>\n",
       "      <td>25593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S2FQ</td>\n",
       "      <td>5459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_id  text_toks_n\n",
       "0    S2EF        16644\n",
       "1    S2CY         2706\n",
       "2    S2AJ         4161\n",
       "3    S2B5         7372\n",
       "4    S2DD        11452\n",
       "5    S2A5         1897\n",
       "6    S2AX        14492\n",
       "7    S2E2         4883\n",
       "8    S2C9        25593\n",
       "9    S2FQ         5459"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tokens = pd.DataFrame(texts_tokens)\n",
    "texts_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index and call it text_id\n",
    "meta_texts_merge = meta_texts.reset_index().rename(columns={'index': 'text_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_texts = pd.merge(\n",
    "    left=meta_texts_merge,\n",
    "    right=texts_tokens,\n",
    "    on='text_id'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>rec_length</th>\n",
       "      <th>rec_date</th>\n",
       "      <th>rec_year</th>\n",
       "      <th>rec_period</th>\n",
       "      <th>n_speakers</th>\n",
       "      <th>list_speakers</th>\n",
       "      <th>rec_loc</th>\n",
       "      <th>relationships</th>\n",
       "      <th>topics</th>\n",
       "      <th>activity</th>\n",
       "      <th>conv_type</th>\n",
       "      <th>conventions</th>\n",
       "      <th>in_sample</th>\n",
       "      <th>transcriber</th>\n",
       "      <th>text_toks_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S2A5</td>\n",
       "      <td>0:12:20</td>\n",
       "      <td>2014-08-28</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014_Q3</td>\n",
       "      <td>2</td>\n",
       "      <td>S0024 S0144</td>\n",
       "      <td>Speakers' home</td>\n",
       "      <td>Close family, partners, very close friends</td>\n",
       "      <td>meeting; making arrangements for going to loca...</td>\n",
       "      <td>Partners have a chat about jetlag and babies.</td>\n",
       "      <td>Discussing</td>\n",
       "      <td>Revised</td>\n",
       "      <td>y</td>\n",
       "      <td>T15</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S2AJ</td>\n",
       "      <td>0:19:24</td>\n",
       "      <td>2015-08-04</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015_Q3</td>\n",
       "      <td>2</td>\n",
       "      <td>S0439 S0441</td>\n",
       "      <td>Home - kitchen</td>\n",
       "      <td>Close family, partners, very close friends</td>\n",
       "      <td>Food, old school friends, complaining about th...</td>\n",
       "      <td>Catch-up with housemate.</td>\n",
       "      <td>Discussing, explaining, inquiring, complaining...</td>\n",
       "      <td>Revised</td>\n",
       "      <td>y</td>\n",
       "      <td>T19</td>\n",
       "      <td>4161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S2AX</td>\n",
       "      <td>1:03:29</td>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012_Q2</td>\n",
       "      <td>2</td>\n",
       "      <td>S0037 S0115</td>\n",
       "      <td>ANON and ANON’s home, Cambridge</td>\n",
       "      <td>Close family, partners, very close friends</td>\n",
       "      <td>Music, elitism, magazines, dreams, Christmas d...</td>\n",
       "      <td>ANON and ANON talking while listening to the r...</td>\n",
       "      <td>Discussing, explaining, anecdote telling</td>\n",
       "      <td>Original</td>\n",
       "      <td>y</td>\n",
       "      <td>T15</td>\n",
       "      <td>14492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S2B5</td>\n",
       "      <td>0:36:03</td>\n",
       "      <td>2012-03-06</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012_Q1</td>\n",
       "      <td>2</td>\n",
       "      <td>S0024 S0144</td>\n",
       "      <td>The Swan pub, Norfolk</td>\n",
       "      <td>Close family, partners, very close friends</td>\n",
       "      <td>Dogs, property, economics, health</td>\n",
       "      <td>Husband and wife discuss some issues over a dr...</td>\n",
       "      <td>Discussing, explaining</td>\n",
       "      <td>Original</td>\n",
       "      <td>y</td>\n",
       "      <td>T20</td>\n",
       "      <td>7372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S2C9</td>\n",
       "      <td>2:12:08</td>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015_Q1</td>\n",
       "      <td>2</td>\n",
       "      <td>S0336 S0362</td>\n",
       "      <td>Speaker's home</td>\n",
       "      <td>Friends, wider family circle</td>\n",
       "      <td>Friends, family, work, holidays, festivals, ho...</td>\n",
       "      <td>Friends catching up</td>\n",
       "      <td>Discussing, explaining, inquiring, complaining...</td>\n",
       "      <td>Revised</td>\n",
       "      <td>n</td>\n",
       "      <td>T10</td>\n",
       "      <td>25593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S2CY</td>\n",
       "      <td>0:14:25</td>\n",
       "      <td>2015-11-27</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015_Q4</td>\n",
       "      <td>2</td>\n",
       "      <td>S0679 S0680</td>\n",
       "      <td>ANON’s living room, Leeds</td>\n",
       "      <td>Close family, partners, very close friends</td>\n",
       "      <td>Computers, Work colleagues in computing, Furni...</td>\n",
       "      <td>Late evening chat</td>\n",
       "      <td>Discussing, anecdote telling, making arrangements</td>\n",
       "      <td>Revised</td>\n",
       "      <td>n</td>\n",
       "      <td>T04</td>\n",
       "      <td>2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S2DD</td>\n",
       "      <td>1:04:04</td>\n",
       "      <td>2016-06-21</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016_Q2</td>\n",
       "      <td>4</td>\n",
       "      <td>S0687 S0688 S0689 S0690</td>\n",
       "      <td>A restaurant, Istria, Croatia</td>\n",
       "      <td>Close family, partners, very close friends</td>\n",
       "      <td>Food, Drink, Weather, Cities and towns in Istr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discussing, explaining, inquiring</td>\n",
       "      <td>Revised</td>\n",
       "      <td>n</td>\n",
       "      <td>T10</td>\n",
       "      <td>11452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S2E2</td>\n",
       "      <td>0:23:55</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012_Q2</td>\n",
       "      <td>2</td>\n",
       "      <td>S0030 S0096</td>\n",
       "      <td>The university, Salford</td>\n",
       "      <td>Colleagues</td>\n",
       "      <td>CVs</td>\n",
       "      <td>Colleagues Talking about Writing a CV</td>\n",
       "      <td>Discussing, explaining, advising</td>\n",
       "      <td>Original</td>\n",
       "      <td>y</td>\n",
       "      <td>T11</td>\n",
       "      <td>4883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1:25:40</td>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016_Q1</td>\n",
       "      <td>4</td>\n",
       "      <td>S0567 S0611 S0620 S0623</td>\n",
       "      <td>All speakers’ rented uni home, Lancaster</td>\n",
       "      <td>Close family, partners, very close friends</td>\n",
       "      <td>Discussing/eating food, bedrooms, maths, Sugar...</td>\n",
       "      <td>Talking while eating pizza with housemates</td>\n",
       "      <td>Discussing, explaining, inquiring, anecdote te...</td>\n",
       "      <td>Revised</td>\n",
       "      <td>n</td>\n",
       "      <td>T10</td>\n",
       "      <td>16644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S2FQ</td>\n",
       "      <td>0:37:35</td>\n",
       "      <td>2014-09-05</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014_Q3</td>\n",
       "      <td>2</td>\n",
       "      <td>S0261 S0262</td>\n",
       "      <td>House-sitting in Australia</td>\n",
       "      <td>Close family, partners, very close friends</td>\n",
       "      <td>social story-telling, problem-solving techniqu...</td>\n",
       "      <td>A couple discussing their ideas for innovative...</td>\n",
       "      <td>Discussing, explaining, inquiring, advising, r...</td>\n",
       "      <td>Revised</td>\n",
       "      <td>y</td>\n",
       "      <td>T19</td>\n",
       "      <td>5459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_id rec_length    rec_date  rec_year rec_period  n_speakers  \\\n",
       "0    S2A5    0:12:20  2014-08-28      2014    2014_Q3           2   \n",
       "1    S2AJ    0:19:24  2015-08-04      2015    2015_Q3           2   \n",
       "2    S2AX    1:03:29  2012-04-01      2012    2012_Q2           2   \n",
       "3    S2B5    0:36:03  2012-03-06      2012    2012_Q1           2   \n",
       "4    S2C9    2:12:08  2015-02-24      2015    2015_Q1           2   \n",
       "5    S2CY    0:14:25  2015-11-27      2015    2015_Q4           2   \n",
       "6    S2DD    1:04:04  2016-06-21      2016    2016_Q2           4   \n",
       "7    S2E2    0:23:55  2012-04-16      2012    2012_Q2           2   \n",
       "8    S2EF    1:25:40  2016-01-10      2016    2016_Q1           4   \n",
       "9    S2FQ    0:37:35  2014-09-05      2014    2014_Q3           2   \n",
       "\n",
       "             list_speakers                                   rec_loc  \\\n",
       "0              S0024 S0144                            Speakers' home   \n",
       "1              S0439 S0441                            Home - kitchen   \n",
       "2              S0037 S0115           ANON and ANON’s home, Cambridge   \n",
       "3              S0024 S0144                     The Swan pub, Norfolk   \n",
       "4              S0336 S0362                            Speaker's home   \n",
       "5              S0679 S0680                 ANON’s living room, Leeds   \n",
       "6  S0687 S0688 S0689 S0690             A restaurant, Istria, Croatia   \n",
       "7              S0030 S0096                   The university, Salford   \n",
       "8  S0567 S0611 S0620 S0623  All speakers’ rented uni home, Lancaster   \n",
       "9              S0261 S0262                House-sitting in Australia   \n",
       "\n",
       "                                relationships  \\\n",
       "0  Close family, partners, very close friends   \n",
       "1  Close family, partners, very close friends   \n",
       "2  Close family, partners, very close friends   \n",
       "3  Close family, partners, very close friends   \n",
       "4                Friends, wider family circle   \n",
       "5  Close family, partners, very close friends   \n",
       "6  Close family, partners, very close friends   \n",
       "7                                  Colleagues   \n",
       "8  Close family, partners, very close friends   \n",
       "9  Close family, partners, very close friends   \n",
       "\n",
       "                                              topics  \\\n",
       "0  meeting; making arrangements for going to loca...   \n",
       "1  Food, old school friends, complaining about th...   \n",
       "2  Music, elitism, magazines, dreams, Christmas d...   \n",
       "3                  Dogs, property, economics, health   \n",
       "4  Friends, family, work, holidays, festivals, ho...   \n",
       "5  Computers, Work colleagues in computing, Furni...   \n",
       "6  Food, Drink, Weather, Cities and towns in Istr...   \n",
       "7                                                CVs   \n",
       "8  Discussing/eating food, bedrooms, maths, Sugar...   \n",
       "9  social story-telling, problem-solving techniqu...   \n",
       "\n",
       "                                            activity  \\\n",
       "0      Partners have a chat about jetlag and babies.   \n",
       "1                          Catch-up with housemate.    \n",
       "2  ANON and ANON talking while listening to the r...   \n",
       "3  Husband and wife discuss some issues over a dr...   \n",
       "4                                Friends catching up   \n",
       "5                                  Late evening chat   \n",
       "6                                                NaN   \n",
       "7              Colleagues Talking about Writing a CV   \n",
       "8         Talking while eating pizza with housemates   \n",
       "9  A couple discussing their ideas for innovative...   \n",
       "\n",
       "                                           conv_type conventions in_sample  \\\n",
       "0                                         Discussing     Revised         y   \n",
       "1  Discussing, explaining, inquiring, complaining...     Revised         y   \n",
       "2           Discussing, explaining, anecdote telling    Original         y   \n",
       "3                             Discussing, explaining    Original         y   \n",
       "4  Discussing, explaining, inquiring, complaining...     Revised         n   \n",
       "5  Discussing, anecdote telling, making arrangements     Revised         n   \n",
       "6                  Discussing, explaining, inquiring     Revised         n   \n",
       "7                   Discussing, explaining, advising    Original         y   \n",
       "8  Discussing, explaining, inquiring, anecdote te...     Revised         n   \n",
       "9  Discussing, explaining, inquiring, advising, r...     Revised         y   \n",
       "\n",
       "  transcriber  text_toks_n  \n",
       "0         T15         1897  \n",
       "1         T19         4161  \n",
       "2         T15        14492  \n",
       "3         T20         7372  \n",
       "4         T10        25593  \n",
       "5         T04         2706  \n",
       "6         T10        11452  \n",
       "7         T11         4883  \n",
       "8         T10        16644  \n",
       "9         T19         5459  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not testing:\n",
    "    meta_texts.to_csv('../out/texts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = []\n",
    "\n",
    "for text in texts:\n",
    "    for u in text.findall('u'):\n",
    "        u_d = {}\n",
    "        u_d['text_id'] = text.get('id')\n",
    "        u_d['u_n'] = u.get('n')\n",
    "        u_d['u_who'] = u.get('who')\n",
    "        u_d['u_trans'] = u.get('trans')\n",
    "        u_d['u_whoConfidence'] = u.get('whoConfidence')\n",
    "        u_d['u_toks_n'] = len(list(u.iter('w')))\n",
    "        utterances.append(u_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = pd.DataFrame(utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>u_n</th>\n",
       "      <th>u_who</th>\n",
       "      <th>u_trans</th>\n",
       "      <th>u_whoConfidence</th>\n",
       "      <th>u_toks_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1</td>\n",
       "      <td>S0567</td>\n",
       "      <td>nonoverlap</td>\n",
       "      <td>high</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>2</td>\n",
       "      <td>S0623</td>\n",
       "      <td>nonoverlap</td>\n",
       "      <td>high</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>3</td>\n",
       "      <td>S0620</td>\n",
       "      <td>nonoverlap</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>4</td>\n",
       "      <td>S0623</td>\n",
       "      <td>nonoverlap</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>5</td>\n",
       "      <td>S0620</td>\n",
       "      <td>nonoverlap</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8803</th>\n",
       "      <td>S2FQ</td>\n",
       "      <td>239</td>\n",
       "      <td>S0261</td>\n",
       "      <td>nonoverlap</td>\n",
       "      <td>high</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>S2FQ</td>\n",
       "      <td>240</td>\n",
       "      <td>S0262</td>\n",
       "      <td>nonoverlap</td>\n",
       "      <td>high</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8805</th>\n",
       "      <td>S2FQ</td>\n",
       "      <td>241</td>\n",
       "      <td>S0261</td>\n",
       "      <td>nonoverlap</td>\n",
       "      <td>high</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8806</th>\n",
       "      <td>S2FQ</td>\n",
       "      <td>242</td>\n",
       "      <td>S0262</td>\n",
       "      <td>nonoverlap</td>\n",
       "      <td>high</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8807</th>\n",
       "      <td>S2FQ</td>\n",
       "      <td>243</td>\n",
       "      <td>S0261</td>\n",
       "      <td>nonoverlap</td>\n",
       "      <td>high</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8808 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_id  u_n  u_who     u_trans u_whoConfidence  u_toks_n\n",
       "0       S2EF    1  S0567  nonoverlap            high        12\n",
       "1       S2EF    2  S0623  nonoverlap            high         8\n",
       "2       S2EF    3  S0620  nonoverlap            high         1\n",
       "3       S2EF    4  S0623  nonoverlap            high         0\n",
       "4       S2EF    5  S0620  nonoverlap            high         4\n",
       "...      ...  ...    ...         ...             ...       ...\n",
       "8803    S2FQ  239  S0261  nonoverlap            high        52\n",
       "8804    S2FQ  240  S0262  nonoverlap            high        12\n",
       "8805    S2FQ  241  S0261  nonoverlap            high         9\n",
       "8806    S2FQ  242  S0262  nonoverlap            high         7\n",
       "8807    S2FQ  243  S0261  nonoverlap            high         8\n",
       "\n",
       "[8808 rows x 6 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not testing:\n",
    "    utterances.to_csv('../out/utterances.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_speakers_head = pd.read_csv(\n",
    "    fp_meta_speakers_fields,\n",
    "    delimiter='\\t',\n",
    "    skiprows=1,\n",
    "    index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_speakers = pd.read_csv(\n",
    "    fp_meta_speakers, \n",
    "    delimiter='\\t', \n",
    "    names=meta_speakers_head['XML tag'],\n",
    "    index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exactage</th>\n",
       "      <th>age1994</th>\n",
       "      <th>agerange</th>\n",
       "      <th>gender</th>\n",
       "      <th>nat</th>\n",
       "      <th>birthplace</th>\n",
       "      <th>birthcountry</th>\n",
       "      <th>l1</th>\n",
       "      <th>lingorig</th>\n",
       "      <th>dialect_rep</th>\n",
       "      <th>...</th>\n",
       "      <th>dialect_l2</th>\n",
       "      <th>dialect_l3</th>\n",
       "      <th>dialect_l4</th>\n",
       "      <th>edqual</th>\n",
       "      <th>occupation</th>\n",
       "      <th>socgrade</th>\n",
       "      <th>nssec</th>\n",
       "      <th>l2</th>\n",
       "      <th>fls</th>\n",
       "      <th>in_core</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0001</th>\n",
       "      <td>32</td>\n",
       "      <td>25_34</td>\n",
       "      <td>30_39</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Wordsley, West Midlands</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>None indicated</td>\n",
       "      <td>...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>University researcher</td>\n",
       "      <td>A</td>\n",
       "      <td>1_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0002</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>19_29</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>Midlands</td>\n",
       "      <td>...</td>\n",
       "      <td>england</td>\n",
       "      <td>midlands</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japanese -- Intermediate</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>19_29</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Royal Leamington Spa, Warwickshire</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>Northern</td>\n",
       "      <td>...</td>\n",
       "      <td>england</td>\n",
       "      <td>north</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>4_graduate</td>\n",
       "      <td>Student</td>\n",
       "      <td>E</td>\n",
       "      <td>uncat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30_39</td>\n",
       "      <td>M</td>\n",
       "      <td>British</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germany</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>Northern</td>\n",
       "      <td>...</td>\n",
       "      <td>england</td>\n",
       "      <td>north</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>C2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spanish -- Beginner</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0005</th>\n",
       "      <td>NaN</td>\n",
       "      <td>60plus</td>\n",
       "      <td>80_89</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>Midlands</td>\n",
       "      <td>...</td>\n",
       "      <td>england</td>\n",
       "      <td>midlands</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>2_secondary</td>\n",
       "      <td>Insurance Broker (retired)</td>\n",
       "      <td>E</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>French -- Beginner</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0691</th>\n",
       "      <td>45</td>\n",
       "      <td>45_59</td>\n",
       "      <td>40_49</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Barrow-In-Furness</td>\n",
       "      <td>UK</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>Northern/ Cumbrian</td>\n",
       "      <td>...</td>\n",
       "      <td>england</td>\n",
       "      <td>north</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>3_sixthform</td>\n",
       "      <td>dental nurse (trainee)</td>\n",
       "      <td>D</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0692</th>\n",
       "      <td>22</td>\n",
       "      <td>15_24</td>\n",
       "      <td>19_29</td>\n",
       "      <td>M</td>\n",
       "      <td>British</td>\n",
       "      <td>Barrow-in-Furness</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>Northern</td>\n",
       "      <td>...</td>\n",
       "      <td>england</td>\n",
       "      <td>north</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>3_sixthform</td>\n",
       "      <td>Sales Assistant (Part time)</td>\n",
       "      <td>D</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNKFEMALE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None indicated</td>\n",
       "      <td>...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>9_unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNKMALE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None indicated</td>\n",
       "      <td>...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>9_unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNKMULTI</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None indicated</td>\n",
       "      <td>...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>9_unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          exactage  age1994 agerange gender      nat  \\\n",
       "S0001           32    25_34    30_39      F  British   \n",
       "S0002          NaN  Unknown    19_29      F  British   \n",
       "S0003          NaN  Unknown    19_29      F  British   \n",
       "S0004          NaN  Unknown    30_39      M  British   \n",
       "S0005          NaN   60plus    80_89      F  British   \n",
       "...            ...      ...      ...    ...      ...   \n",
       "S0691           45    45_59    40_49      F  British   \n",
       "S0692           22    15_24    19_29      M  British   \n",
       "UNKFEMALE      NaN  Unknown  Unknown      F      NaN   \n",
       "UNKMALE        NaN  Unknown  Unknown      M      NaN   \n",
       "UNKMULTI       NaN  Unknown  Unknown      X      NaN   \n",
       "\n",
       "                                   birthplace birthcountry       l1 lingorig  \\\n",
       "S0001                 Wordsley, West Midlands      England  English  England   \n",
       "S0002                              Birmingham      England  English  England   \n",
       "S0003      Royal Leamington Spa, Warwickshire      England  English  England   \n",
       "S0004                                     NaN      Germany  English  England   \n",
       "S0005                              Birmingham      England  English  England   \n",
       "...                                       ...          ...      ...      ...   \n",
       "S0691                       Barrow-In-Furness           UK  English  England   \n",
       "S0692                       Barrow-in-Furness      England  English  England   \n",
       "UNKFEMALE                                 NaN          NaN      NaN      NaN   \n",
       "UNKMALE                                   NaN          NaN      NaN      NaN   \n",
       "UNKMULTI                                  NaN          NaN      NaN      NaN   \n",
       "\n",
       "                  dialect_rep  ...   dialect_l2   dialect_l3   dialect_l4  \\\n",
       "S0001          None indicated  ...  unspecified  unspecified  unspecified   \n",
       "S0002                Midlands  ...      england     midlands  unspecified   \n",
       "S0003                Northern  ...      england        north  unspecified   \n",
       "S0004                Northern  ...      england        north  unspecified   \n",
       "S0005                Midlands  ...      england     midlands  unspecified   \n",
       "...                       ...  ...          ...          ...          ...   \n",
       "S0691      Northern/ Cumbrian  ...      england        north  unspecified   \n",
       "S0692                Northern  ...      england        north  unspecified   \n",
       "UNKFEMALE      None indicated  ...  unspecified  unspecified  unspecified   \n",
       "UNKMALE        None indicated  ...  unspecified  unspecified  unspecified   \n",
       "UNKMULTI       None indicated  ...  unspecified  unspecified  unspecified   \n",
       "\n",
       "                edqual                   occupation socgrade    nssec   l2  \\\n",
       "S0001       5_postgrad        University researcher        A      1_2  NaN   \n",
       "S0002       5_postgrad                      Teacher        B        2  NaN   \n",
       "S0003       4_graduate                      Student        E    uncat  NaN   \n",
       "S0004       5_postgrad                     Engineer       C2        5  NaN   \n",
       "S0005      2_secondary   Insurance Broker (retired)        E        8  NaN   \n",
       "...                ...                          ...      ...      ...  ...   \n",
       "S0691      3_sixthform       dental nurse (trainee)        D        6  NaN   \n",
       "S0692      3_sixthform  Sales Assistant (Part time)        D        6  NaN   \n",
       "UNKFEMALE    9_unknown                          NaN  unknown  unknown  NaN   \n",
       "UNKMALE      9_unknown                          NaN  unknown  unknown  NaN   \n",
       "UNKMULTI     9_unknown                          NaN  unknown  unknown  NaN   \n",
       "\n",
       "                                fls in_core  \n",
       "S0001                           NaN       n  \n",
       "S0002      Japanese -- Intermediate       n  \n",
       "S0003                           NaN       n  \n",
       "S0004           Spanish -- Beginner       n  \n",
       "S0005            French -- Beginner       n  \n",
       "...                             ...     ...  \n",
       "S0691                           NaN       y  \n",
       "S0692                           NaN       n  \n",
       "UNKFEMALE                       NaN       n  \n",
       "UNKMALE                         NaN       n  \n",
       "UNKMULTI                        NaN       n  \n",
       "\n",
       "[671 rows x 24 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_speakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add number of tokens per speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_toks = defaultdict(int)\n",
    "\n",
    "for text in texts:\n",
    "    for u in text.iter('u'):\n",
    "        who = u.get('who')\n",
    "        n_words = len([w for w in u.iter('w')])\n",
    "        speakers_toks[who] += n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_toks = pd.DataFrame(list(speakers_toks.items()), columns=['who', 'speaker_toks_n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>who</th>\n",
       "      <th>speaker_toks_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S0336</td>\n",
       "      <td>14332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S0362</td>\n",
       "      <td>11261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S0115</td>\n",
       "      <td>7522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S0037</td>\n",
       "      <td>6970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0623</td>\n",
       "      <td>6621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S0024</td>\n",
       "      <td>5086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S0611</td>\n",
       "      <td>4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S0144</td>\n",
       "      <td>4183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S0687</td>\n",
       "      <td>3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S0261</td>\n",
       "      <td>3596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      who  speaker_toks_n\n",
       "20  S0336           14332\n",
       "21  S0362           11261\n",
       "16  S0115            7522\n",
       "17  S0037            6970\n",
       "1   S0623            6621\n",
       "11  S0024            5086\n",
       "5   S0611            4698\n",
       "10  S0144            4183\n",
       "14  S0687            3810\n",
       "22  S0261            3596"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_toks.sort_values(by='speaker_toks_n', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_speakers_merge = meta_speakers.reset_index().rename(columns={'index': 'who'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_speakers = pd.merge(\n",
    "    left=meta_speakers_merge,\n",
    "    right=speaker_toks,\n",
    "    on='who'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>who</th>\n",
       "      <th>exactage</th>\n",
       "      <th>age1994</th>\n",
       "      <th>agerange</th>\n",
       "      <th>gender</th>\n",
       "      <th>nat</th>\n",
       "      <th>birthplace</th>\n",
       "      <th>birthcountry</th>\n",
       "      <th>l1</th>\n",
       "      <th>lingorig</th>\n",
       "      <th>...</th>\n",
       "      <th>dialect_l3</th>\n",
       "      <th>dialect_l4</th>\n",
       "      <th>edqual</th>\n",
       "      <th>occupation</th>\n",
       "      <th>socgrade</th>\n",
       "      <th>nssec</th>\n",
       "      <th>l2</th>\n",
       "      <th>fls</th>\n",
       "      <th>in_core</th>\n",
       "      <th>speaker_toks_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0024</td>\n",
       "      <td>36</td>\n",
       "      <td>35_44</td>\n",
       "      <td>30_39</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>south</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>lecturer</td>\n",
       "      <td>A</td>\n",
       "      <td>1_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>5086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>40_49</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>London</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>south</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>Careers Consultant</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>2622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>19_29</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Sunderland, Tyne and Wear</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>north</td>\n",
       "      <td>northeast</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>Research Manager</td>\n",
       "      <td>A</td>\n",
       "      <td>1_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>6970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30_39</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>York</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>north</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>Careers Consultant</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>Kutchi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30_39</td>\n",
       "      <td>M</td>\n",
       "      <td>British</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>midlands</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>PhD student</td>\n",
       "      <td>A</td>\n",
       "      <td>1_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>French -- Advanced; German -- Advanced</td>\n",
       "      <td>n</td>\n",
       "      <td>7522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S0144</td>\n",
       "      <td>36</td>\n",
       "      <td>35_44</td>\n",
       "      <td>30_39</td>\n",
       "      <td>M</td>\n",
       "      <td>British</td>\n",
       "      <td>London</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>south</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>Lecturer</td>\n",
       "      <td>A</td>\n",
       "      <td>1_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>4183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S0261</td>\n",
       "      <td>41</td>\n",
       "      <td>35_44</td>\n",
       "      <td>40_49</td>\n",
       "      <td>M</td>\n",
       "      <td>British/New Zealand</td>\n",
       "      <td>Wellington</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>English</td>\n",
       "      <td>England/NZ</td>\n",
       "      <td>...</td>\n",
       "      <td>non_uk</td>\n",
       "      <td>non_uk</td>\n",
       "      <td>4_graduate</td>\n",
       "      <td>Entrepreneur</td>\n",
       "      <td>A</td>\n",
       "      <td>1_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>3596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S0262</td>\n",
       "      <td>41</td>\n",
       "      <td>35_44</td>\n",
       "      <td>40_49</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Dorchester</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>south</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>teacher</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>French -- level unspecified; German -- level u...</td>\n",
       "      <td>y</td>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S0336</td>\n",
       "      <td>24</td>\n",
       "      <td>15_24</td>\n",
       "      <td>19_29</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Wegberg</td>\n",
       "      <td>Germany</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>Administrator</td>\n",
       "      <td>C1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>German -- Beginner</td>\n",
       "      <td>n</td>\n",
       "      <td>14332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S0362</td>\n",
       "      <td>25</td>\n",
       "      <td>25_34</td>\n",
       "      <td>19_29</td>\n",
       "      <td>M</td>\n",
       "      <td>British</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>Coach/Franchise owner</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>11261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S0439</td>\n",
       "      <td>23</td>\n",
       "      <td>15_24</td>\n",
       "      <td>19_29</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>south</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>4_graduate</td>\n",
       "      <td>Project Co-ordinator</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S0441</td>\n",
       "      <td>24</td>\n",
       "      <td>15_24</td>\n",
       "      <td>19_29</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>south</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>Mental Health Nurse</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>2129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S0567</td>\n",
       "      <td>20</td>\n",
       "      <td>15_24</td>\n",
       "      <td>19_29</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>UK</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>south</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>4_graduate</td>\n",
       "      <td>student</td>\n",
       "      <td>E</td>\n",
       "      <td>uncat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S0611</td>\n",
       "      <td>20</td>\n",
       "      <td>15_24</td>\n",
       "      <td>19_29</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Wakefield, West Yorkshire</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>north</td>\n",
       "      <td>yorkshire</td>\n",
       "      <td>4_graduate</td>\n",
       "      <td>student</td>\n",
       "      <td>E</td>\n",
       "      <td>uncat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spanish -- basic</td>\n",
       "      <td>n</td>\n",
       "      <td>4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S0620</td>\n",
       "      <td>19</td>\n",
       "      <td>15_24</td>\n",
       "      <td>19_29</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Stockport, UK</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>3_sixthform</td>\n",
       "      <td>Student</td>\n",
       "      <td>E</td>\n",
       "      <td>uncat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S0623</td>\n",
       "      <td>20</td>\n",
       "      <td>15_24</td>\n",
       "      <td>19_29</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>north</td>\n",
       "      <td>northwest</td>\n",
       "      <td>4_graduate</td>\n",
       "      <td>student</td>\n",
       "      <td>E</td>\n",
       "      <td>uncat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>6621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S0679</td>\n",
       "      <td>54</td>\n",
       "      <td>45_59</td>\n",
       "      <td>50_59</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Kent, Margate</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>south</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5_postgrad</td>\n",
       "      <td>Retired (University manager)</td>\n",
       "      <td>E</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>French -- level unspecified</td>\n",
       "      <td>y</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S0680</td>\n",
       "      <td>64</td>\n",
       "      <td>60plus</td>\n",
       "      <td>60_69</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Margate, Kent</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>south</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>4_graduate</td>\n",
       "      <td>Retired teacher</td>\n",
       "      <td>E</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>French -- School</td>\n",
       "      <td>y</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S0687</td>\n",
       "      <td>21</td>\n",
       "      <td>15_24</td>\n",
       "      <td>19_29</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Bolton</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>...</td>\n",
       "      <td>north</td>\n",
       "      <td>northwest</td>\n",
       "      <td>4_graduate</td>\n",
       "      <td>Student</td>\n",
       "      <td>E</td>\n",
       "      <td>uncat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spanish -- A-level</td>\n",
       "      <td>y</td>\n",
       "      <td>3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S0688</td>\n",
       "      <td>53</td>\n",
       "      <td>45_59</td>\n",
       "      <td>50_59</td>\n",
       "      <td>F</td>\n",
       "      <td>British</td>\n",
       "      <td>Bolton</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>...</td>\n",
       "      <td>north</td>\n",
       "      <td>northwest</td>\n",
       "      <td>4_graduate</td>\n",
       "      <td>Midwife</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>2987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S0689</td>\n",
       "      <td>16</td>\n",
       "      <td>15_24</td>\n",
       "      <td>11_18</td>\n",
       "      <td>M</td>\n",
       "      <td>British</td>\n",
       "      <td>Bolton</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>...</td>\n",
       "      <td>north</td>\n",
       "      <td>northwest</td>\n",
       "      <td>2_secondary</td>\n",
       "      <td>Student</td>\n",
       "      <td>E</td>\n",
       "      <td>uncat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>2832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S0690</td>\n",
       "      <td>53</td>\n",
       "      <td>45_59</td>\n",
       "      <td>50_59</td>\n",
       "      <td>M</td>\n",
       "      <td>British</td>\n",
       "      <td>London</td>\n",
       "      <td>England</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>...</td>\n",
       "      <td>south</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>4_graduate</td>\n",
       "      <td>Management Consultant</td>\n",
       "      <td>A</td>\n",
       "      <td>1_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>1782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UNKFEMALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>9_unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UNKMULTI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>9_unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          who exactage  age1994 agerange gender                  nat  \\\n",
       "0       S0024       36    35_44    30_39      F              British   \n",
       "1       S0030      NaN  Unknown    40_49      F              British   \n",
       "2       S0037      NaN  Unknown    19_29      F              British   \n",
       "3       S0096      NaN  Unknown    30_39      F              British   \n",
       "4       S0115      NaN  Unknown    30_39      M              British   \n",
       "5       S0144       36    35_44    30_39      M              British   \n",
       "6       S0261       41    35_44    40_49      M  British/New Zealand   \n",
       "7       S0262       41    35_44    40_49      F              British   \n",
       "8       S0336       24    15_24    19_29      F              British   \n",
       "9       S0362       25    25_34    19_29      M              British   \n",
       "10      S0439       23    15_24    19_29      F              British   \n",
       "11      S0441       24    15_24    19_29      F              British   \n",
       "12      S0567       20    15_24    19_29      F              British   \n",
       "13      S0611       20    15_24    19_29      F              British   \n",
       "14      S0620       19    15_24    19_29      F              British   \n",
       "15      S0623       20    15_24    19_29      F              British   \n",
       "16      S0679       54    45_59    50_59      F              British   \n",
       "17      S0680       64   60plus    60_69      F              British   \n",
       "18      S0687       21    15_24    19_29      F              British   \n",
       "19      S0688       53    45_59    50_59      F              British   \n",
       "20      S0689       16    15_24    11_18      M              British   \n",
       "21      S0690       53    45_59    50_59      M              British   \n",
       "22  UNKFEMALE      NaN  Unknown  Unknown      F                  NaN   \n",
       "23   UNKMULTI      NaN  Unknown  Unknown      X                  NaN   \n",
       "\n",
       "                   birthplace birthcountry       l1    lingorig  ...  \\\n",
       "0                     Norwich      England  English     England  ...   \n",
       "1                      London      England  English     England  ...   \n",
       "2   Sunderland, Tyne and Wear      England  English     England  ...   \n",
       "3                        York      England  English     England  ...   \n",
       "4                  Birmingham      England  English     England  ...   \n",
       "5                      London      England  English     England  ...   \n",
       "6                  Wellington  New Zealand  English  England/NZ  ...   \n",
       "7                  Dorchester      England  English     England  ...   \n",
       "8                     Wegberg      Germany  English     England  ...   \n",
       "9                   Leicester      England  English     England  ...   \n",
       "10                         UK           UK  English     England  ...   \n",
       "11                         UK           UK  English     England  ...   \n",
       "12                 Birmingham           UK  English     England  ...   \n",
       "13  Wakefield, West Yorkshire      England  English     England  ...   \n",
       "14              Stockport, UK      England  English     England  ...   \n",
       "15                 Manchester      England  English     England  ...   \n",
       "16              Kent, Margate      England  English     England  ...   \n",
       "17              Margate, Kent      England  English     England  ...   \n",
       "18                     Bolton      England  English          UK  ...   \n",
       "19                     Bolton      England  English          UK  ...   \n",
       "20                     Bolton      England  English          UK  ...   \n",
       "21                     London      England  English          UK  ...   \n",
       "22                        NaN          NaN      NaN         NaN  ...   \n",
       "23                        NaN          NaN      NaN         NaN  ...   \n",
       "\n",
       "     dialect_l3   dialect_l4       edqual                    occupation  \\\n",
       "0         south  unspecified   5_postgrad                      lecturer   \n",
       "1         south  unspecified   5_postgrad            Careers Consultant   \n",
       "2         north    northeast   5_postgrad              Research Manager   \n",
       "3         north  unspecified   5_postgrad            Careers Consultant   \n",
       "4      midlands  unspecified   5_postgrad                   PhD student   \n",
       "5         south  unspecified   5_postgrad                      Lecturer   \n",
       "6        non_uk       non_uk   4_graduate                  Entrepreneur   \n",
       "7         south  unspecified   5_postgrad                       teacher   \n",
       "8   unspecified  unspecified   5_postgrad                 Administrator   \n",
       "9   unspecified  unspecified   5_postgrad         Coach/Franchise owner   \n",
       "10        south  unspecified   4_graduate          Project Co-ordinator   \n",
       "11        south  unspecified   5_postgrad           Mental Health Nurse   \n",
       "12        south  unspecified   4_graduate                       student   \n",
       "13        north    yorkshire   4_graduate                       student   \n",
       "14  unspecified  unspecified  3_sixthform                       Student   \n",
       "15        north    northwest   4_graduate                       student   \n",
       "16        south  unspecified   5_postgrad  Retired (University manager)   \n",
       "17        south  unspecified   4_graduate               Retired teacher   \n",
       "18        north    northwest   4_graduate                       Student   \n",
       "19        north    northwest   4_graduate                       Midwife   \n",
       "20        north    northwest  2_secondary                       Student   \n",
       "21        south  unspecified   4_graduate         Management Consultant   \n",
       "22  unspecified  unspecified    9_unknown                           NaN   \n",
       "23  unspecified  unspecified    9_unknown                           NaN   \n",
       "\n",
       "   socgrade    nssec      l2  \\\n",
       "0         A      1_2     NaN   \n",
       "1         B        2     NaN   \n",
       "2         A      1_2     NaN   \n",
       "3         B        2  Kutchi   \n",
       "4         A      1_2     NaN   \n",
       "5         A      1_2     NaN   \n",
       "6         A      1_2     NaN   \n",
       "7         B        2     NaN   \n",
       "8        C1        3     NaN   \n",
       "9         B        2     NaN   \n",
       "10        B        2     NaN   \n",
       "11        B        2     NaN   \n",
       "12        E    uncat     NaN   \n",
       "13        E    uncat     NaN   \n",
       "14        E    uncat     NaN   \n",
       "15        E    uncat     NaN   \n",
       "16        E        8     NaN   \n",
       "17        E        8     NaN   \n",
       "18        E    uncat     NaN   \n",
       "19        B        2     NaN   \n",
       "20        E    uncat     NaN   \n",
       "21        A      1_2     NaN   \n",
       "22  unknown  unknown     NaN   \n",
       "23  unknown  unknown     NaN   \n",
       "\n",
       "                                                  fls in_core speaker_toks_n  \n",
       "0                                                 NaN       n           5086  \n",
       "1                                                 NaN       n           2622  \n",
       "2                                                 NaN       n           6970  \n",
       "3                                                 NaN       n           2261  \n",
       "4              French -- Advanced; German -- Advanced       n           7522  \n",
       "5                                                 NaN       y           4183  \n",
       "6                                                 NaN       n           3596  \n",
       "7   French -- level unspecified; German -- level u...       y           1863  \n",
       "8                                  German -- Beginner       n          14332  \n",
       "9                                                 NaN       y          11261  \n",
       "10                                                NaN       n           2032  \n",
       "11                                                NaN       y           2129  \n",
       "12                                                NaN       n           2784  \n",
       "13                                   Spanish -- basic       n           4698  \n",
       "14                                                NaN       n           2488  \n",
       "15                                                NaN       y           6621  \n",
       "16                        French -- level unspecified       y            848  \n",
       "17                                   French -- School       y           1858  \n",
       "18                                 Spanish -- A-level       y           3810  \n",
       "19                                                NaN       y           2987  \n",
       "20                                                NaN       y           2832  \n",
       "21                                                NaN       n           1782  \n",
       "22                                                NaN       n             91  \n",
       "23                                                NaN       n              3  \n",
       "\n",
       "[24 rows x 26 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_speakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not testing:\n",
    "    meta_speakers.to_csv('../out/speakers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the metadata present in the corpus, I’ve added the following columns:\n",
    "\n",
    "- `w_idx`: token position (‘index’) in the given utterance, starting at 1\n",
    "- `w_L1`: preceding token\n",
    "- `w_R1`: subsequent token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "for text in texts:\n",
    "    tok_d = {}\n",
    "    tok_d['text_id'] = text.get('id')\n",
    "\n",
    "    for u in text.findall('u'):\n",
    "        tok_d['u_n'] = u.get('n')\n",
    "\n",
    "        u_toks = list(u.iter('w'))\n",
    "        for i, w in enumerate(u_toks):\n",
    "            tok_d['w_pos'] = w.get('pos')\n",
    "            tok_d['w_lemma'] = w.get('lemma')\n",
    "            tok_d['w_class'] = w.get('class')\n",
    "            tok_d['w_usas'] = w.get('usas')\n",
    "            tok_d['w_text'] = w.text\n",
    "            tok_d['w_idx'] = i + 1\n",
    "            tok_d['w_L1'] = u_toks[i-1].text if i > 0 else '<s>'\n",
    "            tok_d['w_R1'] = u_toks[i+1].text if i < len(u_toks) - 1 else '</s>'\n",
    "\n",
    "            tokens.append(tok_d.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pd.DataFrame(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>u_n</th>\n",
       "      <th>w_pos</th>\n",
       "      <th>w_lemma</th>\n",
       "      <th>w_class</th>\n",
       "      <th>w_usas</th>\n",
       "      <th>w_text</th>\n",
       "      <th>w_idx</th>\n",
       "      <th>w_L1</th>\n",
       "      <th>w_R1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1</td>\n",
       "      <td>VM</td>\n",
       "      <td>shall</td>\n",
       "      <td>VERB</td>\n",
       "      <td>T1:1:3</td>\n",
       "      <td>shall</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1</td>\n",
       "      <td>PPIS1</td>\n",
       "      <td>i</td>\n",
       "      <td>PRON</td>\n",
       "      <td>Z8</td>\n",
       "      <td>I</td>\n",
       "      <td>2</td>\n",
       "      <td>shall</td>\n",
       "      <td>move</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1</td>\n",
       "      <td>VVI</td>\n",
       "      <td>move</td>\n",
       "      <td>VERB</td>\n",
       "      <td>M2</td>\n",
       "      <td>move</td>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1</td>\n",
       "      <td>AT</td>\n",
       "      <td>the</td>\n",
       "      <td>ART</td>\n",
       "      <td>Z5</td>\n",
       "      <td>the</td>\n",
       "      <td>4</td>\n",
       "      <td>move</td>\n",
       "      <td>laptops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1</td>\n",
       "      <td>NN2</td>\n",
       "      <td>laptop</td>\n",
       "      <td>SUBST</td>\n",
       "      <td>Y2</td>\n",
       "      <td>laptops</td>\n",
       "      <td>5</td>\n",
       "      <td>the</td>\n",
       "      <td>then</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1</td>\n",
       "      <td>RT</td>\n",
       "      <td>then</td>\n",
       "      <td>ADV</td>\n",
       "      <td>N4</td>\n",
       "      <td>then</td>\n",
       "      <td>6</td>\n",
       "      <td>laptops</td>\n",
       "      <td>stick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1</td>\n",
       "      <td>VV0</td>\n",
       "      <td>stick</td>\n",
       "      <td>VERB</td>\n",
       "      <td>M2</td>\n",
       "      <td>stick</td>\n",
       "      <td>7</td>\n",
       "      <td>then</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1</td>\n",
       "      <td>PPH1</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>Z8</td>\n",
       "      <td>it</td>\n",
       "      <td>8</td>\n",
       "      <td>stick</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1</td>\n",
       "      <td>II</td>\n",
       "      <td>on</td>\n",
       "      <td>PREP</td>\n",
       "      <td>N6</td>\n",
       "      <td>on</td>\n",
       "      <td>9</td>\n",
       "      <td>it</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1</td>\n",
       "      <td>AT</td>\n",
       "      <td>the</td>\n",
       "      <td>ART</td>\n",
       "      <td>N6</td>\n",
       "      <td>the</td>\n",
       "      <td>10</td>\n",
       "      <td>on</td>\n",
       "      <td>table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1</td>\n",
       "      <td>NN1</td>\n",
       "      <td>table</td>\n",
       "      <td>SUBST</td>\n",
       "      <td>N6</td>\n",
       "      <td>table</td>\n",
       "      <td>11</td>\n",
       "      <td>the</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>1</td>\n",
       "      <td>YQUE</td>\n",
       "      <td>PUNC</td>\n",
       "      <td>STOP</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>12</td>\n",
       "      <td>table</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>2</td>\n",
       "      <td>UH</td>\n",
       "      <td>yeah</td>\n",
       "      <td>INTERJ</td>\n",
       "      <td>Z4</td>\n",
       "      <td>yeah</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>2</td>\n",
       "      <td>VD0</td>\n",
       "      <td>do</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Z5</td>\n",
       "      <td>do</td>\n",
       "      <td>2</td>\n",
       "      <td>yeah</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>2</td>\n",
       "      <td>PPIS2</td>\n",
       "      <td>we</td>\n",
       "      <td>PRON</td>\n",
       "      <td>Z8</td>\n",
       "      <td>we</td>\n",
       "      <td>3</td>\n",
       "      <td>do</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>2</td>\n",
       "      <td>VVI</td>\n",
       "      <td>want</td>\n",
       "      <td>VERB</td>\n",
       "      <td>X7</td>\n",
       "      <td>want</td>\n",
       "      <td>4</td>\n",
       "      <td>we</td>\n",
       "      <td>plates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>2</td>\n",
       "      <td>NN2</td>\n",
       "      <td>plate</td>\n",
       "      <td>SUBST</td>\n",
       "      <td>O2</td>\n",
       "      <td>plates</td>\n",
       "      <td>5</td>\n",
       "      <td>want</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>2</td>\n",
       "      <td>CC</td>\n",
       "      <td>or</td>\n",
       "      <td>CONJ</td>\n",
       "      <td>Z5</td>\n",
       "      <td>or</td>\n",
       "      <td>6</td>\n",
       "      <td>plates</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>2</td>\n",
       "      <td>UH</td>\n",
       "      <td>no</td>\n",
       "      <td>INTERJ</td>\n",
       "      <td>Z4</td>\n",
       "      <td>no</td>\n",
       "      <td>7</td>\n",
       "      <td>or</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S2EF</td>\n",
       "      <td>2</td>\n",
       "      <td>YQUE</td>\n",
       "      <td>PUNC</td>\n",
       "      <td>STOP</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>8</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id u_n  w_pos w_lemma w_class  w_usas   w_text  w_idx     w_L1  \\\n",
       "0     S2EF   1     VM   shall    VERB  T1:1:3    shall      1      <s>   \n",
       "1     S2EF   1  PPIS1       i    PRON      Z8        I      2    shall   \n",
       "2     S2EF   1    VVI    move    VERB      M2     move      3        I   \n",
       "3     S2EF   1     AT     the     ART      Z5      the      4     move   \n",
       "4     S2EF   1    NN2  laptop   SUBST      Y2  laptops      5      the   \n",
       "5     S2EF   1     RT    then     ADV      N4     then      6  laptops   \n",
       "6     S2EF   1    VV0   stick    VERB      M2    stick      7     then   \n",
       "7     S2EF   1   PPH1      it    PRON      Z8       it      8    stick   \n",
       "8     S2EF   1     II      on    PREP      N6       on      9       it   \n",
       "9     S2EF   1     AT     the     ART      N6      the     10       on   \n",
       "10    S2EF   1    NN1   table   SUBST      N6    table     11      the   \n",
       "11    S2EF   1   YQUE    PUNC    STOP                ?     12    table   \n",
       "12    S2EF   2     UH    yeah  INTERJ      Z4     yeah      1      <s>   \n",
       "13    S2EF   2    VD0      do    VERB      Z5       do      2     yeah   \n",
       "14    S2EF   2  PPIS2      we    PRON      Z8       we      3       do   \n",
       "15    S2EF   2    VVI    want    VERB      X7     want      4       we   \n",
       "16    S2EF   2    NN2   plate   SUBST      O2   plates      5     want   \n",
       "17    S2EF   2     CC      or    CONJ      Z5       or      6   plates   \n",
       "18    S2EF   2     UH      no  INTERJ      Z4       no      7       or   \n",
       "19    S2EF   2   YQUE    PUNC    STOP                ?      8       no   \n",
       "\n",
       "       w_R1  \n",
       "0         I  \n",
       "1      move  \n",
       "2       the  \n",
       "3   laptops  \n",
       "4      then  \n",
       "5     stick  \n",
       "6        it  \n",
       "7        on  \n",
       "8       the  \n",
       "9     table  \n",
       "10        ?  \n",
       "11     </s>  \n",
       "12       do  \n",
       "13       we  \n",
       "14     want  \n",
       "15   plates  \n",
       "16       or  \n",
       "17       no  \n",
       "18        ?  \n",
       "19     </s>  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(tokens) == tokens_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I export the full token table to `tokens.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not testing:\n",
    "    tokens.to_csv('../out/tokens.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also export a smaller version for use in spreadsheet software. This version contains the first 50,000 tokens in the corpus and is stored in `tokens_50k.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not testing:\n",
    "    (tokens\n",
    "     .head(50_000)\n",
    "     .to_csv('../out/tokens_50k.csv', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge tokens with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94659 entries, 0 to 94658\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text_id  94659 non-null  object\n",
      " 1   u_n      94659 non-null  object\n",
      " 2   w_pos    94659 non-null  object\n",
      " 3   w_lemma  94659 non-null  object\n",
      " 4   w_class  94659 non-null  object\n",
      " 5   w_usas   94659 non-null  object\n",
      " 6   w_text   94659 non-null  object\n",
      " 7   w_idx    94659 non-null  int64 \n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "tokens.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## + utterance information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_utt = pd.merge(\n",
    "    tokens,\n",
    "    utterances,\n",
    "    on = ['text_id', 'u_n']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 94659 entries, 0 to 94658\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   text_id          94659 non-null  object\n",
      " 1   u_n              94659 non-null  object\n",
      " 2   w_pos            94659 non-null  object\n",
      " 3   w_lemma          94659 non-null  object\n",
      " 4   w_class          94659 non-null  object\n",
      " 5   w_usas           94659 non-null  object\n",
      " 6   w_text           94659 non-null  object\n",
      " 7   w_idx            94659 non-null  int64 \n",
      " 8   u_who            94659 non-null  object\n",
      " 9   u_trans          94659 non-null  object\n",
      " 10  u_whoConfidence  94659 non-null  object\n",
      " 11  u_toks_n         94659 non-null  int64 \n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "toks_utt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## + text information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_utt_text = pd.merge(\n",
    "    toks_utt,\n",
    "    meta_texts,\n",
    "    on = 'text_id'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 94659 entries, 0 to 94658\n",
      "Data columns (total 27 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   text_id          94659 non-null  object\n",
      " 1   u_n              94659 non-null  object\n",
      " 2   w_pos            94659 non-null  object\n",
      " 3   w_lemma          94659 non-null  object\n",
      " 4   w_class          94659 non-null  object\n",
      " 5   w_usas           94659 non-null  object\n",
      " 6   w_text           94659 non-null  object\n",
      " 7   w_idx            94659 non-null  int64 \n",
      " 8   u_who            94659 non-null  object\n",
      " 9   u_trans          94659 non-null  object\n",
      " 10  u_whoConfidence  94659 non-null  object\n",
      " 11  u_toks_n         94659 non-null  int64 \n",
      " 12  rec_length       94659 non-null  object\n",
      " 13  rec_date         94659 non-null  object\n",
      " 14  rec_year         94659 non-null  int64 \n",
      " 15  rec_period       94659 non-null  object\n",
      " 16  n_speakers       94659 non-null  int64 \n",
      " 17  list_speakers    94659 non-null  object\n",
      " 18  rec_loc          94659 non-null  object\n",
      " 19  relationships    94659 non-null  object\n",
      " 20  topics           94659 non-null  object\n",
      " 21  activity         83207 non-null  object\n",
      " 22  conv_type        94659 non-null  object\n",
      " 23  conventions      94659 non-null  object\n",
      " 24  in_sample        94659 non-null  object\n",
      " 25  transcriber      94659 non-null  object\n",
      " 26  text_toks_n      94659 non-null  int64 \n",
      "dtypes: int64(5), object(22)\n",
      "memory usage: 20.2+ MB\n"
     ]
    }
   ],
   "source": [
    "toks_utt_text.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## + speaker information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_utt_text_speakers = pd.merge(\n",
    "    toks_utt_text,\n",
    "    meta_speakers,\n",
    "    left_on = 'u_who',\n",
    "    right_on = 'who'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 94659 entries, 0 to 94658\n",
      "Data columns (total 53 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   text_id          94659 non-null  object\n",
      " 1   u_n              94659 non-null  object\n",
      " 2   w_pos            94659 non-null  object\n",
      " 3   w_lemma          94659 non-null  object\n",
      " 4   w_class          94659 non-null  object\n",
      " 5   w_usas           94659 non-null  object\n",
      " 6   w_text           94659 non-null  object\n",
      " 7   w_idx            94659 non-null  int64 \n",
      " 8   u_who            94659 non-null  object\n",
      " 9   u_trans          94659 non-null  object\n",
      " 10  u_whoConfidence  94659 non-null  object\n",
      " 11  u_toks_n         94659 non-null  int64 \n",
      " 12  rec_length       94659 non-null  object\n",
      " 13  rec_date         94659 non-null  object\n",
      " 14  rec_year         94659 non-null  int64 \n",
      " 15  rec_period       94659 non-null  object\n",
      " 16  n_speakers       94659 non-null  int64 \n",
      " 17  list_speakers    94659 non-null  object\n",
      " 18  rec_loc          94659 non-null  object\n",
      " 19  relationships    94659 non-null  object\n",
      " 20  topics           94659 non-null  object\n",
      " 21  activity         83207 non-null  object\n",
      " 22  conv_type        94659 non-null  object\n",
      " 23  conventions      94659 non-null  object\n",
      " 24  in_sample        94659 non-null  object\n",
      " 25  transcriber      94659 non-null  object\n",
      " 26  text_toks_n      94659 non-null  int64 \n",
      " 27  who              94659 non-null  object\n",
      " 28  exactage         75190 non-null  object\n",
      " 29  age1994          94659 non-null  object\n",
      " 30  agerange         94659 non-null  object\n",
      " 31  gender           94659 non-null  object\n",
      " 32  nat              94565 non-null  object\n",
      " 33  birthplace       94565 non-null  object\n",
      " 34  birthcountry     94565 non-null  object\n",
      " 35  l1               94565 non-null  object\n",
      " 36  lingorig         94565 non-null  object\n",
      " 37  dialect_rep      94659 non-null  object\n",
      " 38  hab_city         89106 non-null  object\n",
      " 39  hab_country      94565 non-null  object\n",
      " 40  hab_dur          94565 non-null  object\n",
      " 41  dialect_l1       94659 non-null  object\n",
      " 42  dialect_l2       94659 non-null  object\n",
      " 43  dialect_l3       94659 non-null  object\n",
      " 44  dialect_l4       94659 non-null  object\n",
      " 45  edqual           94659 non-null  object\n",
      " 46  occupation       94565 non-null  object\n",
      " 47  socgrade         94659 non-null  object\n",
      " 48  nssec            94659 non-null  object\n",
      " 49  l2               2261 non-null   object\n",
      " 50  fls              34931 non-null  object\n",
      " 51  in_core          94659 non-null  object\n",
      " 52  speaker_toks_n   94659 non-null  int64 \n",
      "dtypes: int64(6), object(47)\n",
      "memory usage: 39.0+ MB\n"
     ]
    }
   ],
   "source": [
    "toks_utt_text_speakers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not testing:\n",
    "    toks_utt_text_speakers.to_csv('../out/tokens-plus-meta.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 94659\n",
      "file size: 64.40 MB\n"
     ]
    }
   ],
   "source": [
    "print(f'number of rows: {len(toks_utt_text_speakers)}')\n",
    "print(f'file size: {os.path.getsize(\"../out/tokens-plus-meta.csv\") / 1_000_000:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also write out a small version containing the first 50,000 rows for use in spreadsheet software:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not testing:\n",
    "    toks_utt_text_speakers.iloc[:50_000].to_csv(\n",
    "        '../out/tokens-plus-meta_small.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 50000\n",
      "file size: 40.04 MB\n"
     ]
    }
   ],
   "source": [
    "print(f'number of rows: {len(toks_utt_text_speakers.iloc[:50_000])}')\n",
    "print(f'file size: {os.path.getsize(\"../out/tokens-plus-meta_small.csv\") / 1_000_000:.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('bncparse')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
